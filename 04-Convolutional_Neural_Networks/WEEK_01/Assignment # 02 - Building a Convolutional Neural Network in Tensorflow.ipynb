{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnnutils import *\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6204c374be26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the data (signs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 6\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig / 255 \n",
    "X_test = X_test_orig / 255\n",
    "y_train = convert_to_one_hot(y_train_orig, 6).T\n",
    "y_test = convert_to_one_hot(y_test_orig, 6).T\n",
    "\n",
    "print('Number of Training examples: ' + str(X_train[0].shape))\n",
    "print('Number o Testing examples: ' + str(X_test[0].shape))\n",
    "print('X_train shape :' + str(X_train.shape))\n",
    "print('X_test shape: ' + str(X_test.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))\n",
    "\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for Tensorflow sessions \n",
    "    \n",
    "    n_H0 -- height of an image \n",
    "    n_W0 -- width of an image \n",
    "    n_C0 -- number of channels \n",
    "    n_y -- numbers of labels / classes \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    X -- placeholder for data input, of the shape [None, n_H0, n_W0, n_C0] and dtype float \n",
    "    y -- plachehoder for the input label, of the shape [None, n_C] and dtype float \n",
    "    \n",
    "    \"\"\"\n",
    "    X = tf.placeholders(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    y = tf.placeholders(tf.float32, [None, n_y])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_placeholders(64, 64, 3, 6)\n",
    "\n",
    "print('X = ', str(X))\n",
    "print('y = ', str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializa_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    \n",
    "    parameters = {'W1': W1,\n",
    "                 'W2': W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # clears the default graph stack and resets the global default graph\n",
    "\n",
    "with tf.Session as sess_test: # starts the session and runs Tensorflow operations\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variable_initializer() # initializes global variables \n",
    "    sess_test.run(init)\n",
    "    \n",
    "    print('W1', str(parameters['W1'].eval()[1,1,1]))\n",
    "    print('W2', str(parameters['W2'].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11965718  0.76097522 -0.15622847 -0.14938278 -0.81229329  1.41810875]\n",
      " [-0.17224219  1.83776388 -2.06872358  0.90547537  1.47696846  0.39939721]\n",
      " [-1.12241691  0.77380528 -0.74917192 -1.87323102 -1.05564885 -1.00743207]\n",
      " [ 0.28079674  0.96892259  0.66151353  1.50333779 -0.24210554 -0.49013245]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "y = np.random.randn(4,6)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-54944e67a41f>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-54944e67a41f>\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    if print_cost = True and epoch % 1 == 0:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def model(X_Train, Y_Train, X_test, Y_test, learning_rate=0.009, \n",
    "          num_epochs=100, minibatch_size=64, print_cost=True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    m, n_H0, n_W0, n_C0 = X_Train.shape\n",
    "    n_y = Y_Train.shape[1]\n",
    "    costs = []\n",
    "    \n",
    "    # initialize placeholders \n",
    "    X, Y = create_placehoders(n_H0, n_W0, n_C0, n_y)\n",
    "    \n",
    "    # initializer parameters \n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # forward propagation \n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # compute cost \n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # initialize the optimizer \n",
    "    optimizer = optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # initializing the variables \n",
    "    init = tf.global_variable_initializer()\n",
    "    \n",
    "    # running he session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            minibatch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            seed += 1\n",
    "            \n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                minibatch_X, minibatch_Y = minibatches \n",
    "                \n",
    "                _, temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, y:minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print('Cost after epoch %i: %f' % (epoch, minibatch_cost))\n",
    "                \n",
    "            if print_cost = True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                \n",
    "            # plot the results \n",
    "            plt.plot(np.squeeze(costs))\n",
    "            plt.xlabel('Cost')\n",
    "            plt.ylabel('Iterations')\n",
    "            plt.title('Learning Rate = ' + str(learning_rate))\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            # Calculate the correct predictions \n",
    "            predict_op = tf.argmax(Z3, 1)\n",
    "            correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "            # Calculate accuracy on the test set\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print(accuracy)\n",
    "            train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "            test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "            print(\"Train Accuracy:\", train_accuracy)\n",
    "            print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "            return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
